{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Kq6boXs1TLJT",
        "dMYMO97rr7Ue"
      ],
      "authorship_tag": "ABX9TyMTy/CL+rQPMK4OhavcwWOM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FadelYang/craft-it-object-detection-model/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing required Libraries\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "metadata": {
        "id": "4JnzJf9euig4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing Dataset"
      ],
      "metadata": {
        "id": "JF0A5Q_zr742"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount to Google Drive"
      ],
      "metadata": {
        "id": "Kq6boXs1TLJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEaz1G0zTKTt",
        "outputId": "a469f639-005c-44bf-cbfb-aab855e13581"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/'Colab Notebooks'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tD5l4odTyKL",
        "outputId": "02c3b31f-95d7-4fe2-877c-0bf63497dde3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect To Kaggle And Download Datasets\n",
        "\n",
        "this code is used to connect Google Colab and Kaggle, run it just once for download the datasets from kaggle, uncomment it first if you want to run these cell below"
      ],
      "metadata": {
        "id": "dMYMO97rr7Ue"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KsZwNJQ-rrQw"
      },
      "outputs": [],
      "source": [
        "# # copy kaggle.json to /root/.kaggle/ folder so that kaggle cli can access it.\n",
        "# !mkdir /.kaggle\n",
        "# !mv kaggle.json /.kaggle\n",
        "# !mv /.kaggle /root/\n",
        "# !chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Download datasets from Kaggle.\n",
        "# !kaggle datasets download -d kshitizgajurel042/recyclable-images-with-annotations-for-detection"
      ],
      "metadata": {
        "collapsed": true,
        "id": "G3GnlennsTme"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip recyclable-images-with-annotations-for-detection.zip"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5Gnid9mNsVsn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mv 'Final Data' recyclable-images-datasets"
      ],
      "metadata": {
        "id": "7Z5zSDEMtMCY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess Dataset"
      ],
      "metadata": {
        "id": "Z5pkqwAkt3Qm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function for read annotations\n",
        "def read_annotations(annotation_file):\n",
        "  with open(annotation_file, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "    annotations = []\n",
        "    for line in lines:\n",
        "      parts = line.strip().split()\n",
        "      class_label = parts[0]\n",
        "      x_min, y_min, x_max, y_max = map(float, parts[1:])\n",
        "      annotations.append({\n",
        "          'class_label': class_label,\n",
        "          'x_min': x_min,\n",
        "          'y_min': y_min,\n",
        "          'x_max': x_max,\n",
        "          'y_max': y_max\n",
        "      })\n",
        "    return annotations"
      ],
      "metadata": {
        "id": "0jvTZiT8t6no"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing data\n",
        "data_dir = os.path.join(os.getcwd(), 'recyclable-images-datasets')\n",
        "\n",
        "def preprocess_data(data_dir, image_size=(224, 224)):\n",
        "  images = []\n",
        "  annotations = []\n",
        "\n",
        "  image_folder = os.path.join(data_dir, 'images', 'train')\n",
        "  label_folder = os.path.join(data_dir, 'labels', 'train')\n",
        "\n",
        "  for image_filename in os.listdir(image_folder):\n",
        "    if image_filename.endswith('.jpg') or image_filename.endswith('.png'):\n",
        "      image_path = os.path.join(image_folder, image_filename)\n",
        "      annotation_filename = image_filename.replace('.jpg', '.txt').replace('.png', '.txt')\n",
        "      annotation_path = os.path.join(label_folder, annotation_filename)\n",
        "\n",
        "      image = tf.io.read_file(image_path)\n",
        "      image = tf.image.decode_jpeg(image, channels=3)\n",
        "      image = tf.image.resize(image, image_size)\n",
        "      image = image / 255.0  # Normalize image\n",
        "\n",
        "      if os.path.exists(annotation_path):\n",
        "        annotation = read_annotations(annotation_path)\n",
        "        images.append(image.numpy())\n",
        "        annotations.append(annotation)\n",
        "      else:\n",
        "        print(f'Annotation file for image {image_filename} not found')\n",
        "\n",
        "  return np.array(images), annotations"
      ],
      "metadata": {
        "id": "kjjq7D7MJunf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, annotations = preprocess_data(data_dir)"
      ],
      "metadata": {
        "id": "KdsvesA2Cf0o"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check images and annotations\n",
        "print(images[0])\n",
        "for i in range(10):\n",
        "  print(annotations[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQtnTHapTY1a",
        "outputId": "fef9f04a-6b10-4e96-db55-f05a7a1242f4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0.27056822 0.36860743 0.35292116]\n",
            "  [0.17833133 0.27244896 0.28645456]\n",
            "  [0.22577031 0.31988794 0.35910362]\n",
            "  ...\n",
            "  [0.1996989  0.5485591  0.1304109 ]\n",
            "  [0.32925162 0.6434772  0.19305716]\n",
            "  [0.07933023 0.4224483  0.00338119]]\n",
            "\n",
            " [[0.19367747 0.29479793 0.2829732 ]\n",
            "  [0.1520008  0.24985994 0.2632053 ]\n",
            "  [0.2302521  0.32436976 0.36862746]\n",
            "  ...\n",
            "  [0.30458388 0.565807   0.2168885 ]\n",
            "  [0.48093227 0.62242895 0.33517385]\n",
            "  [0.19287176 0.45509842 0.08192892]]\n",
            "\n",
            " [[0.20880353 0.31860748 0.32991198]\n",
            "  [0.22517009 0.3232093  0.3557023 ]\n",
            "  [0.24901962 0.33921573 0.40096042]\n",
            "  ...\n",
            "  [0.36376947 0.5478396  0.2500437 ]\n",
            "  [0.5184473  0.49403778 0.34949958]\n",
            "  [0.30157393 0.475986   0.15575583]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.48795503 0.6047618  0.70700264]\n",
            "  [0.44093588 0.5851936  0.6854737 ]\n",
            "  [0.4523808  0.63137245 0.7215685 ]\n",
            "  ...\n",
            "  [0.7579829  0.8599437  0.96582603]\n",
            "  [0.74509805 0.84705883 0.9529412 ]\n",
            "  [0.76498616 0.86694694 0.9728293 ]]\n",
            "\n",
            " [[0.48543417 0.59097636 0.69859946]\n",
            "  [0.3947579  0.5354741  0.6423769 ]\n",
            "  [0.4405962  0.6103441  0.7083833 ]\n",
            "  ...\n",
            "  [0.76220465 0.8641654  0.9700478 ]\n",
            "  [0.74509805 0.84705883 0.9529412 ]\n",
            "  [0.7602843  0.8622451  0.9681274 ]]\n",
            "\n",
            " [[0.5005604  0.5980394  0.7159666 ]\n",
            "  [0.39978012 0.5336737  0.65048045]\n",
            "  [0.432493   0.6008404  0.70308125]\n",
            "  ...\n",
            "  [0.76722676 0.86918753 0.9750699 ]\n",
            "  [0.74509805 0.84705883 0.9529412 ]\n",
            "  [0.7535017  0.85546255 0.9613449 ]]]\n",
            "[{'class_label': '6', 'x_min': 0.55625, 'y_min': 0.485156, 'x_max': 0.125, 'y_max': 0.082812}]\n",
            "[{'class_label': '4', 'x_min': 0.752344, 'y_min': 0.535156, 'x_max': 0.054688, 'y_max': 0.229687}]\n",
            "[{'class_label': '4', 'x_min': 0.160156, 'y_min': 0.269531, 'x_max': 0.092188, 'y_max': 0.145313}]\n",
            "[{'class_label': '4', 'x_min': 0.576562, 'y_min': 0.553906, 'x_max': 0.490625, 'y_max': 0.167187}]\n",
            "[{'class_label': '6', 'x_min': 0.441406, 'y_min': 0.235937, 'x_max': 0.026562, 'y_max': 0.025}, {'class_label': '6', 'x_min': 0.290625, 'y_min': 0.854688, 'x_max': 0.05, 'y_max': 0.05}, {'class_label': '6', 'x_min': 0.401562, 'y_min': 0.615625, 'x_max': 0.071875, 'y_max': 0.05}]\n",
            "[{'class_label': '6', 'x_min': 0.698438, 'y_min': 0.503125, 'x_max': 0.040625, 'y_max': 0.046875}]\n",
            "[{'class_label': '6', 'x_min': 0.1375, 'y_min': 0.278125, 'x_max': 0.05625, 'y_max': 0.090625}]\n",
            "[{'class_label': '6', 'x_min': 0.303906, 'y_min': 0.780469, 'x_max': 0.032813, 'y_max': 0.029687}]\n",
            "[{'class_label': '8', 'x_min': 0.564844, 'y_min': 0.639062, 'x_max': 0.145313, 'y_max': 0.178125}]\n",
            "[{'class_label': '6', 'x_min': 0.405469, 'y_min': 0.472656, 'x_max': 0.039062, 'y_max': 0.032813}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tf_dataset(images, annotations):\n",
        "  def generator():\n",
        "    for img, ann in zip(images, annotations):\n",
        "      classes = [a['class_label'] for a in ann]\n",
        "      boundary_boxes = [[a['x_min'], a['y_min'], a['x_max'], a['y_max']] for a in ann]\n",
        "      yield img, (np.array(classes, dtype=np.int32), np.array(boundary_boxes, dtype=np.float32))\n",
        "\n",
        "  dataset = tf.data.Dataset.from_generator(\n",
        "      generator,\n",
        "      output_signature=(\n",
        "          tf.TensorSpec(shape=(224, 224, 3), dtype=tf.float32),\n",
        "          (\n",
        "              tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
        "              tf.TensorSpec(shape=(None, 4), dtype=tf.float32)\n",
        "          )\n",
        "      )\n",
        "  )\n",
        "\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "N8sCGb6hV5QF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = create_tf_dataset(images, annotations)"
      ],
      "metadata": {
        "id": "UkcLdbsNfUBU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image, (classes, boxes) in train_dataset.take(1):\n",
        "    print(\"Image shape:\", image.shape)\n",
        "    print(\"Classes:\", classes)\n",
        "    print(\"Boxes:\", boxes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7iE8wwSfdsQ",
        "outputId": "1e966986-a181-4eaf-f00b-fe32fe5a894a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: (224, 224, 3)\n",
            "Classes: tf.Tensor([6], shape=(1,), dtype=int32)\n",
            "Boxes: tf.Tensor([[0.55625  0.485156 0.125    0.082812]], shape=(1, 4), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kBxhBEosKBid"
      }
    }
  ]
}